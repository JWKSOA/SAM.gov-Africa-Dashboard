name: Update SAM.gov DB (nightly)

on:
  schedule:
    # Around US midnight (covers DST with two UTC windows)
    - cron: "30 4 * * *"
    - cron: "30 5 * * *"
  workflow_dispatch:
    inputs:
      run_bootstrap:
        description: "Run historical bootstrap now"
        required: false
        default: "false"

permissions:
  contents: write

jobs:
  update-db:
    runs-on: ubuntu-latest

    env:
      # Tell BOTH scripts to write the DB into the repo's data/ folder
      SAM_DATA_DIR: ${{ github.workspace }}/data
      GITHUB_ACTIONS: "true"

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          persist-credentials: true
          fetch-depth: 0

      - name: Ensure data folder exists
        run: mkdir -p data

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Historical backfill: run if DB doesn't exist OR user explicitly requested it
      - name: Bootstrap historical (first run or when requested)
        if: ${{ hashFiles('data/opportunities.db') == '' || github.event.inputs.run_bootstrap == 'true' }}
        run: |
          echo "Bootstrapping historical dataâ€¦"
          python bootstrap_historical.py

      - name: Daily refresh (always)
        run: |
          python download_and_update.py

- name: Optimize DB size
  run: |
    python optimize_database.py

      # DB maintenance: add helpful indexes + PRAGMA optimize + VACUUM
      - name: Optimize SQLite (indexes + optimize + vacuum)
        run: |
          python - <<'PY'
          import sqlite3, os
          db = "data/opportunities.db"
          if not os.path.exists(db):
              raise SystemExit("DB not found after loaders.")
          con = sqlite3.connect(db)
          cur = con.cursor()
          # Helpful indexes (id is PK and NoticeID is UNIQUE via scripts)
          cur.execute('CREATE INDEX IF NOT EXISTS idx_opps_posteddate ON opportunities ("PostedDate")')
          cur.execute('CREATE INDEX IF NOT EXISTS idx_opps_popcountry ON opportunities ("PopCountry")')
          cur.execute('CREATE INDEX IF NOT EXISTS idx_opps_countrycode ON opportunities ("CountryCode")')
          cur.execute('CREATE INDEX IF NOT EXISTS idx_opps_agency ON opportunities ("Department/Ind.Agency")')
          con.commit()
          cur.execute('PRAGMA optimize;')
          cur.execute('VACUUM;')
          con.commit()
          con.close()
          print("Indexes created; optimize + VACUUM complete.")
          PY

      # Defensive cleanup: make sure no raw CSVs remain before committing
      - name: Remove raw CSVs before commit
        run: |
          rm -f data/ContractOpportunitiesFullCSV_*.csv || true
          rm -f data/*.csv || true

      # Commit & push if anything changed (typically the DB)
      - name: Commit & push DB updates
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          if git diff --cached --quiet; then
            echo "No changes to commit."
          else
            ts=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
            git commit -m "Update opportunities.db (${ts})"
            git push
          fi
